{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.315016746520996, Accuracy: 15.625, Test Loss: 2.3037657737731934, Test Accuracy: 9.600000381469727\n",
      "Epoch 1, Loss: 1.7527433633804321, Accuracy: 54.33168411254883, Test Loss: 1.5834091901779175, Test Accuracy: 45.61499786376953\n",
      "Epoch 1, Loss: 1.1921391487121582, Accuracy: 68.3302230834961, Test Loss: 1.1949607133865356, Test Accuracy: 60.063331604003906\n",
      "Epoch 1, Loss: 0.9341874718666077, Accuracy: 74.8338851928711, Test Loss: 0.9798074960708618, Test Accuracy: 67.64500427246094\n",
      "Epoch 1, Loss: 0.7928770184516907, Accuracy: 78.35879516601562, Test Loss: 0.8417341709136963, Test Accuracy: 72.42599487304688\n",
      "Epoch 1, Loss: 0.695784866809845, Accuracy: 80.83208465576172, Test Loss: 0.741244375705719, Test Accuracy: 75.89833068847656\n",
      "Epoch 1, Loss: 0.6265295743942261, Accuracy: 82.73710632324219, Test Loss: 0.6649223566055298, Test Accuracy: 78.4857177734375\n",
      "Epoch 1, Loss: 0.5710211992263794, Accuracy: 84.2635498046875, Test Loss: 0.6045863032341003, Test Accuracy: 80.49874877929688\n",
      "Epoch 1, Loss: 0.5272058844566345, Accuracy: 85.34644317626953, Test Loss: 0.557120680809021, Test Accuracy: 82.09666442871094\n",
      "Epoch 1, Loss: 0.4920444190502167, Accuracy: 86.27913665771484, Test Loss: 0.5172200202941895, Test Accuracy: 83.41799926757812\n",
      "Epoch 1, Loss: 0.4609123468399048, Accuracy: 87.13162231445312, Test Loss: 0.48391324281692505, Test Accuracy: 84.5263671875\n",
      "Epoch 1, Loss: 0.4381047487258911, Accuracy: 87.73274230957031, Test Loss: 0.45521751046180725, Test Accuracy: 85.4816665649414\n",
      "Epoch 1, Loss: 0.416212797164917, Accuracy: 88.27278900146484, Test Loss: 0.43068984150886536, Test Accuracy: 86.29615020751953\n",
      "Epoch 1, Loss: 0.39669281244277954, Accuracy: 88.7874755859375, Test Loss: 0.4096361994743347, Test Accuracy: 86.99071502685547\n",
      "Epoch 1, Loss: 0.3786264657974243, Accuracy: 89.27105712890625, Test Loss: 0.3906680941581726, Test Accuracy: 87.60200500488281\n",
      "Epoch 1, Loss: 0.3628521263599396, Accuracy: 89.70269775390625, Test Loss: 0.3732908368110657, Test Accuracy: 88.17562103271484\n",
      "Epoch 1, Loss: 0.3488287031650543, Accuracy: 90.10189056396484, Test Loss: 0.35799920558929443, Test Accuracy: 88.67118072509766\n",
      "Epoch 1, Loss: 0.33575639128685, Accuracy: 90.45782470703125, Test Loss: 0.3439503014087677, Test Accuracy: 89.12332916259766\n",
      "Epoch 1, Loss: 0.32399243116378784, Accuracy: 90.77942657470703, Test Loss: 0.3309926688671112, Test Accuracy: 89.54209899902344\n",
      "Epoch 2, Loss: 0.3157656192779541, Accuracy: 90.99646759033203, Test Loss: 0.31959283351898193, Test Accuracy: 89.90449523925781\n",
      "Epoch 2, Loss: 0.30557581782341003, Accuracy: 91.28289031982422, Test Loss: 0.3088468909263611, Test Accuracy: 90.25238037109375\n",
      "Epoch 2, Loss: 0.2964169979095459, Accuracy: 91.52215576171875, Test Loss: 0.29882967472076416, Test Accuracy: 90.5786361694336\n",
      "Epoch 2, Loss: 0.288278192281723, Accuracy: 91.75235748291016, Test Loss: 0.28975388407707214, Test Accuracy: 90.86869049072266\n",
      "Epoch 2, Loss: 0.28057950735092163, Accuracy: 91.96781158447266, Test Loss: 0.2810955047607422, Test Accuracy: 91.14666748046875\n",
      "Epoch 2, Loss: 0.2732008993625641, Accuracy: 92.16119384765625, Test Loss: 0.2733047306537628, Test Accuracy: 91.39599609375\n",
      "Epoch 2, Loss: 0.2667219340801239, Accuracy: 92.32633209228516, Test Loss: 0.26575857400894165, Test Accuracy: 91.63999938964844\n",
      "Epoch 2, Loss: 0.2605355978012085, Accuracy: 92.50775909423828, Test Loss: 0.2587492763996124, Test Accuracy: 91.86296081542969\n",
      "Epoch 2, Loss: 0.2545018792152405, Accuracy: 92.6697998046875, Test Loss: 0.25219061970710754, Test Accuracy: 92.0778579711914\n",
      "Epoch 2, Loss: 0.2490127682685852, Accuracy: 92.8167724609375, Test Loss: 0.2460353523492813, Test Accuracy: 92.27345275878906\n",
      "Epoch 2, Loss: 0.24367444217205048, Accuracy: 92.97200775146484, Test Loss: 0.2406347543001175, Test Accuracy: 92.43999481201172\n",
      "Epoch 2, Loss: 0.23857726156711578, Accuracy: 93.12521362304688, Test Loss: 0.23518577218055725, Test Accuracy: 92.6138687133789\n",
      "Epoch 2, Loss: 0.23386217653751373, Accuracy: 93.2491455078125, Test Loss: 0.23035664856433868, Test Accuracy: 92.76593780517578\n",
      "Epoch 2, Loss: 0.229729562997818, Accuracy: 93.34953308105469, Test Loss: 0.22546997666358948, Test Accuracy: 92.92454528808594\n",
      "Epoch 2, Loss: 0.22545796632766724, Accuracy: 93.46382904052734, Test Loss: 0.2207673341035843, Test Accuracy: 93.07470703125\n",
      "Epoch 2, Loss: 0.22152963280677795, Accuracy: 93.56949615478516, Test Loss: 0.21623408794403076, Test Accuracy: 93.22285461425781\n",
      "Epoch 2, Loss: 0.21732354164123535, Accuracy: 93.69066619873047, Test Loss: 0.21194158494472504, Test Accuracy: 93.35778045654297\n",
      "Epoch 2, Loss: 0.21340641379356384, Accuracy: 93.80767059326172, Test Loss: 0.2079795002937317, Test Accuracy: 93.48135375976562\n",
      "Epoch 2, Loss: 0.20974649488925934, Accuracy: 93.9149169921875, Test Loss: 0.20438064634799957, Test Accuracy: 93.59526062011719\n",
      "Epoch 3, Loss: 0.20697155594825745, Accuracy: 93.99076843261719, Test Loss: 0.20081645250320435, Test Accuracy: 93.70845794677734\n",
      "Epoch 3, Loss: 0.20354904234409332, Accuracy: 94.08919525146484, Test Loss: 0.19723647832870483, Test Accuracy: 93.822998046875\n",
      "Epoch 3, Loss: 0.20034442842006683, Accuracy: 94.18264770507812, Test Loss: 0.1940074861049652, Test Accuracy: 93.92975616455078\n",
      "Epoch 3, Loss: 0.19720491766929626, Accuracy: 94.26992797851562, Test Loss: 0.19104507565498352, Test Accuracy: 94.0199966430664\n",
      "Epoch 3, Loss: 0.19439813494682312, Accuracy: 94.35527038574219, Test Loss: 0.1878504902124405, Test Accuracy: 94.11837768554688\n",
      "Epoch 3, Loss: 0.1914832890033722, Accuracy: 94.43954467773438, Test Loss: 0.18489140272140503, Test Accuracy: 94.21227264404297\n",
      "Epoch 3, Loss: 0.18887215852737427, Accuracy: 94.51778411865234, Test Loss: 0.18204498291015625, Test Accuracy: 94.302001953125\n",
      "Epoch 3, Loss: 0.1862085908651352, Accuracy: 94.59180450439453, Test Loss: 0.17922751605510712, Test Accuracy: 94.39173889160156\n",
      "Epoch 3, Loss: 0.18350765109062195, Accuracy: 94.66944122314453, Test Loss: 0.17652907967567444, Test Accuracy: 94.47723388671875\n",
      "Epoch 3, Loss: 0.18105724453926086, Accuracy: 94.73701477050781, Test Loss: 0.17387959361076355, Test Accuracy: 94.56145477294922\n",
      "Epoch 3, Loss: 0.1787002682685852, Accuracy: 94.80306243896484, Test Loss: 0.1713695377111435, Test Accuracy: 94.6397933959961\n",
      "Epoch 3, Loss: 0.17636583745479584, Accuracy: 94.86961364746094, Test Loss: 0.16902269423007965, Test Accuracy: 94.71540069580078\n",
      "Epoch 3, Loss: 0.1742652952671051, Accuracy: 94.92967987060547, Test Loss: 0.16679657995700836, Test Accuracy: 94.78823852539062\n",
      "Epoch 3, Loss: 0.17207832634449005, Accuracy: 94.98738098144531, Test Loss: 0.16453635692596436, Test Accuracy: 94.8592300415039\n",
      "Epoch 3, Loss: 0.1698867529630661, Accuracy: 95.05254364013672, Test Loss: 0.1623600274324417, Test Accuracy: 94.92584991455078\n",
      "Epoch 3, Loss: 0.16777342557907104, Accuracy: 95.11343383789062, Test Loss: 0.16025395691394806, Test Accuracy: 94.99203491210938\n",
      "Epoch 3, Loss: 0.1659109741449356, Accuracy: 95.16912841796875, Test Loss: 0.15823082625865936, Test Accuracy: 95.05472564697266\n",
      "Epoch 3, Loss: 0.16403815150260925, Accuracy: 95.22450256347656, Test Loss: 0.15636387467384338, Test Accuracy: 95.11250305175781\n",
      "Epoch 3, Loss: 0.16214801371097565, Accuracy: 95.27619171142578, Test Loss: 0.15439310669898987, Test Accuracy: 95.17350769042969\n",
      "Epoch 4, Loss: 0.16087324917316437, Accuracy: 95.30805206298828, Test Loss: 0.15259778499603271, Test Accuracy: 95.2308578491211\n",
      "Epoch 4, Loss: 0.15897999703884125, Accuracy: 95.36106872558594, Test Loss: 0.15091757476329803, Test Accuracy: 95.28406524658203\n",
      "Epoch 4, Loss: 0.15729588270187378, Accuracy: 95.40797424316406, Test Loss: 0.14918416738510132, Test Accuracy: 95.33799743652344\n",
      "Epoch 4, Loss: 0.15555347502231598, Accuracy: 95.45857238769531, Test Loss: 0.14748775959014893, Test Accuracy: 95.39180755615234\n",
      "Epoch 4, Loss: 0.1540115475654602, Accuracy: 95.50386047363281, Test Loss: 0.14582884311676025, Test Accuracy: 95.44483947753906\n",
      "Epoch 4, Loss: 0.15225477516651154, Accuracy: 95.55378723144531, Test Loss: 0.14422005414962769, Test Accuracy: 95.49396514892578\n",
      "Epoch 4, Loss: 0.15075117349624634, Accuracy: 95.59608459472656, Test Loss: 0.14262501895427704, Test Accuracy: 95.54344177246094\n",
      "Epoch 4, Loss: 0.1493423581123352, Accuracy: 95.63260650634766, Test Loss: 0.14104996621608734, Test Accuracy: 95.59276580810547\n",
      "Epoch 4, Loss: 0.1478411853313446, Accuracy: 95.67674255371094, Test Loss: 0.13954627513885498, Test Accuracy: 95.63939666748047\n",
      "Epoch 4, Loss: 0.1463708132505417, Accuracy: 95.7156982421875, Test Loss: 0.13810428977012634, Test Accuracy: 95.68402862548828\n",
      "Epoch 4, Loss: 0.14501015841960907, Accuracy: 95.75394439697266, Test Loss: 0.13681228458881378, Test Accuracy: 95.72441101074219\n",
      "Epoch 4, Loss: 0.1437937319278717, Accuracy: 95.78687286376953, Test Loss: 0.13555416464805603, Test Accuracy: 95.76304626464844\n",
      "Epoch 4, Loss: 0.1425340324640274, Accuracy: 95.82341003417969, Test Loss: 0.13424721360206604, Test Accuracy: 95.8037109375\n",
      "Epoch 4, Loss: 0.14118924736976624, Accuracy: 95.86161041259766, Test Loss: 0.13294975459575653, Test Accuracy: 95.84423065185547\n",
      "Epoch 4, Loss: 0.1399354785680771, Accuracy: 95.89604949951172, Test Loss: 0.13177019357681274, Test Accuracy: 95.87958526611328\n",
      "Epoch 4, Loss: 0.13872171938419342, Accuracy: 95.93302917480469, Test Loss: 0.13052821159362793, Test Accuracy: 95.91780853271484\n",
      "Epoch 4, Loss: 0.13734571635723114, Accuracy: 95.9728775024414, Test Loss: 0.12929321825504303, Test Accuracy: 95.9560775756836\n",
      "Epoch 4, Loss: 0.13603626191616058, Accuracy: 96.0129165649414, Test Loss: 0.12814415991306305, Test Accuracy: 95.99040222167969\n",
      "Epoch 4, Loss: 0.13489636778831482, Accuracy: 96.04556274414062, Test Loss: 0.12703804671764374, Test Accuracy: 96.02407836914062\n",
      "Epoch 5, Loss: 0.13414175808429718, Accuracy: 96.06802368164062, Test Loss: 0.12590426206588745, Test Accuracy: 96.05973815917969\n",
      "Epoch 5, Loss: 0.13298273086547852, Accuracy: 96.10166931152344, Test Loss: 0.12481871247291565, Test Accuracy: 96.09320831298828\n",
      "Epoch 5, Loss: 0.13188707828521729, Accuracy: 96.1328125, Test Loss: 0.12373055517673492, Test Accuracy: 96.1260757446289\n",
      "Epoch 5, Loss: 0.1306762546300888, Accuracy: 96.16755676269531, Test Loss: 0.12266718596220016, Test Accuracy: 96.15950012207031\n",
      "Epoch 5, Loss: 0.12956564128398895, Accuracy: 96.19708251953125, Test Loss: 0.12164909392595291, Test Accuracy: 96.19049072265625\n",
      "Epoch 5, Loss: 0.12849512696266174, Accuracy: 96.22703552246094, Test Loss: 0.1206129863858223, Test Accuracy: 96.22195434570312\n",
      "Epoch 5, Loss: 0.12740790843963623, Accuracy: 96.26126098632812, Test Loss: 0.11960284411907196, Test Accuracy: 96.25361633300781\n",
      "Epoch 5, Loss: 0.1264866590499878, Accuracy: 96.28932189941406, Test Loss: 0.11863372474908829, Test Accuracy: 96.28309631347656\n",
      "Epoch 5, Loss: 0.1254921853542328, Accuracy: 96.31858825683594, Test Loss: 0.11775337904691696, Test Accuracy: 96.31047058105469\n",
      "Epoch 5, Loss: 0.12447858601808548, Accuracy: 96.3490219116211, Test Loss: 0.11678876727819443, Test Accuracy: 96.3402328491211\n",
      "Epoch 5, Loss: 0.12363924831151962, Accuracy: 96.37468719482422, Test Loss: 0.1158616840839386, Test Accuracy: 96.36896514892578\n",
      "Epoch 5, Loss: 0.12268185615539551, Accuracy: 96.40376281738281, Test Loss: 0.11496126651763916, Test Accuracy: 96.39704895019531\n",
      "Epoch 5, Loss: 0.12172737717628479, Accuracy: 96.43000793457031, Test Loss: 0.11406339704990387, Test Accuracy: 96.42471313476562\n",
      "Epoch 5, Loss: 0.12076430767774582, Accuracy: 96.45601654052734, Test Loss: 0.11323307454586029, Test Accuracy: 96.45000457763672\n",
      "Epoch 5, Loss: 0.11986228078603745, Accuracy: 96.48143768310547, Test Loss: 0.11234967410564423, Test Accuracy: 96.47747039794922\n",
      "Epoch 5, Loss: 0.11910513043403625, Accuracy: 96.50247192382812, Test Loss: 0.11149844527244568, Test Accuracy: 96.50347900390625\n",
      "Epoch 5, Loss: 0.1181996762752533, Accuracy: 96.52579498291016, Test Loss: 0.11068664491176605, Test Accuracy: 96.52860260009766\n",
      "Epoch 5, Loss: 0.11732342094182968, Accuracy: 96.55065155029297, Test Loss: 0.10992775112390518, Test Accuracy: 96.55276489257812\n",
      "Epoch 5, Loss: 0.11647135019302368, Accuracy: 96.57563781738281, Test Loss: 0.10914062708616257, Test Accuracy: 96.57684326171875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# use keras.datasets instead of tensorflow.datasets\n",
    "from tensorflow.keras import datasets, layers\n",
    "mnist = datasets.mnist\n",
    "\n",
    "learning_rate = 1e-4\n",
    "keep_prob_rate = 0.7\n",
    "max_epoch = 5\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(32, 7, activation='relu')\n",
    "        self.pool1 = layers.MaxPooling2D()\n",
    "        self.conv2 = layers.Conv2D(64, 5, activation='relu')\n",
    "        self.pool2 = layers.MaxPooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.d1 = layers.Dense(1024, activation='relu')\n",
    "        self.dropout = layers.Dropout(1-keep_prob_rate)\n",
    "        self.d2 = layers.Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "model = MyModel()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for i, (images, labels) in enumerate(train_ds):\n",
    "        train_step(images, labels)\n",
    "        if i % 100 == 0:\n",
    "            for test_images, test_labels in test_ds:\n",
    "                test_step(test_images, test_labels)\n",
    "            template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "            print(template.format(epoch+1,\n",
    "                                  train_loss.result(),\n",
    "                                  train_accuracy.result()*100,\n",
    "                                  test_loss.result(),\n",
    "                                  test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "nndl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
